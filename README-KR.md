# test_cicd_01

Databricks Asset Bundleì„ í™œìš©í•œ CI/CD í…ŒìŠ¤íŠ¸ í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. ì´ í”„ë¡œì íŠ¸ëŠ” Databricks í™˜ê²½ì—ì„œ Python ëª¨ë“ˆê³¼ ë…¸íŠ¸ë¶ì„ íš¨ìœ¨ì ìœ¼ë¡œ ê´€ë¦¬í•˜ê³  ë°°í¬í•˜ê¸° ìœ„í•œ êµ¬ì¡°ì™€ ìœ í‹¸ë¦¬í‹°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

> ğŸ“– **English Documentation**: [README.md](./README.md)

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
test_cicd_01/
â”œâ”€â”€ src/                          # ì†ŒìŠ¤ ì½”ë“œ
â”‚   â”œâ”€â”€ test_cicd_01/            # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚   â”‚   â”œâ”€â”€ main.py              # Spark ê¸°ë°˜ ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
â”‚   â”‚   â””â”€â”€ __init__.py          # íŒ¨í‚¤ì§€ ì´ˆê¸°í™” (v0.0.1)
â”‚   â”œâ”€â”€ module/                  # ê³µí†µ ëª¨ë“ˆ
â”‚   â”‚   â”œâ”€â”€ path_manager.py      # ê²½ë¡œ ê´€ë¦¬ ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â””â”€â”€ util.py              # ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”‚   â”œâ”€â”€ foo/                     # ì˜ˆì œ ëª¨ë“ˆ
â”‚   â”‚   â””â”€â”€ bar.py               # ë¦¬ì†ŒìŠ¤ íŒŒì¼ ì½ê¸° ì˜ˆì œ
â”‚   â”œâ”€â”€ main.ipynb               # ë©”ì¸ ë…¸íŠ¸ë¶ (ëª¨ë“ˆ ì‚¬ìš© ì˜ˆì œ)
â”‚   â””â”€â”€ set_notebook_paths.ipynb # ë…¸íŠ¸ë¶ ê²½ë¡œ ì„¤ì • ìœ í‹¸ë¦¬í‹°
â”œâ”€â”€ resources/                   # ë¦¬ì†ŒìŠ¤ íŒŒì¼
â”‚   â”œâ”€â”€ test_cicd_01.job.yml    # Databricks Job ì •ì˜
â”‚   â””â”€â”€ foo/bar.yml             # ì˜ˆì œ ì„¤ì • íŒŒì¼
â”œâ”€â”€ tests/                       # í…ŒìŠ¤íŠ¸ ì½”ë“œ
â”‚   â”œâ”€â”€ foo/test_read_resource.py
â”‚   â””â”€â”€ module/test_path_manager.py
â”œâ”€â”€ config/                      # ì„¤ì • íŒŒì¼ ë””ë ‰í† ë¦¬
â”œâ”€â”€ databricks.yml              # Databricks Bundle ì„¤ì •
â””â”€â”€ setup.py                    # Python íŒ¨í‚¤ì§€ ì„¤ì •
```

## ì£¼ìš” ê¸°ëŠ¥

### 1. ê²½ë¡œ ê´€ë¦¬ ì‹œìŠ¤í…œ (PathResolver)
- **ì‹±ê¸€í†¤ íŒ¨í„´**ìœ¼ë¡œ êµ¬í˜„ëœ ê²½ë¡œ ê´€ë¦¬ í´ë˜ìŠ¤
- Databricks í™˜ê²½ì—ì„œ Bundle ë‚´ ë‹¤ì–‘í•œ ë””ë ‰í† ë¦¬ì— ëŒ€í•œ ì ˆëŒ€ ê²½ë¡œ ì œê³µ
- ì§€ì› ê²½ë¡œ: `resources`, `config`, `tests`

```python
from module.path_manager import PathResolver

paths = PathResolver()
print(paths.resources)  # ë¦¬ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ
print(paths.config)     # ì„¤ì • ë””ë ‰í† ë¦¬ ê²½ë¡œ
print(paths.tests)      # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
```

### 2. ë…¸íŠ¸ë¶ ê²½ë¡œ ì„¤ì •
- `set_notebook_paths.ipynb`: Databricks ë…¸íŠ¸ë¶ì—ì„œ Python ëª¨ë“ˆì„ importí•  ìˆ˜ ìˆë„ë¡ sys.path ìë™ ì„¤ì •
- Bundle ì´ë¦„ ê¸°ë°˜ ë™ì  ê²½ë¡œ êµ¬ì„±

### 3. ë¦¬ì†ŒìŠ¤ íŒŒì¼ ê´€ë¦¬
- YAML ì„¤ì • íŒŒì¼ ì½ê¸° ì˜ˆì œ
- ê²½ë¡œ ê´€ë¦¬ìë¥¼ í†µí•œ ì•ˆì „í•œ íŒŒì¼ ì ‘ê·¼

```python
from foo.bar import parse_bar
content = parse_bar()  # resources/foo/bar.yml íŒŒì¼ ì½ê¸°
```

## ì‹œì‘í•˜ê¸°

### 1. í™˜ê²½ ì„¤ì •

Databricks CLI ì„¤ì¹˜:
```bash
pip install databricks-cli
```

Databricks ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì¸ì¦:
```bash
databricks configure
```

### 2. ê°œë°œ í™˜ê²½ ë°°í¬

ê°œë°œ í™˜ê²½ì— ë°°í¬:
```bash
databricks bundle deploy --target dev
```

í”„ë¡œë•ì…˜ í™˜ê²½ì— ë°°í¬:
```bash
databricks bundle deploy --target prod
```

### 3. Job ì‹¤í–‰

ë°°í¬ëœ Job ì‹¤í–‰:
```bash
databricks bundle run
```

### 4. ë¡œì»¬ ê°œë°œ

ê°œë°œ ì˜ì¡´ì„± ì„¤ì¹˜:
```bash
pip install -r requirements-dev.txt
```

í…ŒìŠ¤íŠ¸ ì‹¤í–‰:
```bash
pytest
```

## í…ŒìŠ¤íŠ¸

í”„ë¡œì íŠ¸ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í…ŒìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

- **ê²½ë¡œ ê´€ë¦¬ì í…ŒìŠ¤íŠ¸**: PathResolver í´ë˜ìŠ¤ì˜ ì •ìƒ ë™ì‘ í™•ì¸
- **ë¦¬ì†ŒìŠ¤ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸**: YAML íŒŒì¼ ì½ê¸° ê¸°ëŠ¥ ê²€ì¦

```bash
# ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest

# íŠ¹ì • í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest tests/module/test_path_manager.py
pytest tests/foo/test_read_resource.py
```

## ê°œë°œ ë„êµ¬

- **Databricks Connect**: ë¡œì»¬ IDEì—ì„œ Databricks í´ëŸ¬ìŠ¤í„°ì— ì—°ê²°
- **Visual Studio Code Extension**: Databricks ê°œë°œ í™˜ê²½ í†µí•©
- **pytest**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬

## CI/CD ì„¤ì •

ì´ í”„ë¡œì íŠ¸ëŠ” Databricks Asset Bundleì„ ì‚¬ìš©í•˜ì—¬ CI/CD íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•©ë‹ˆë‹¤:

- **Git ì—°ë™**: GitHub ë¦¬í¬ì§€í† ë¦¬ ê¸°ë°˜ ì†ŒìŠ¤ ê´€ë¦¬
- **ìë™ ë°°í¬**: Bundleì„ í†µí•œ ê°œë°œ/í”„ë¡œë•ì…˜ í™˜ê²½ ë¶„ë¦¬
- **Job ìŠ¤ì¼€ì¤„ë§**: ì›Œí¬í”Œë¡œìš° ìë™ ì‹¤í–‰ ì§€ì›

ìì„¸í•œ ë‚´ìš©ì€ [Databricks Asset Bundles ë¬¸ì„œ](https://docs.databricks.com/dev-tools/bundles/index.html)ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.

## í”„ë¡œì íŠ¸ êµ¬ì„± ìš”ì†Œ

### í•µì‹¬ ëª¨ë“ˆ

#### PathResolver (`src/module/path_manager.py`)
```python
class PathResolver:
    """
    ì‹±ê¸€í†¤ íŒ¨í„´ìœ¼ë¡œ êµ¬í˜„ëœ ê²½ë¡œ ê´€ë¦¬ í´ë˜ìŠ¤
    Databricks Bundle í™˜ê²½ì—ì„œ ì•ˆì „í•œ íŒŒì¼ ê²½ë¡œ ì ‘ê·¼ì„ ì œê³µ
    """
    
    @property
    def resources(self):
        """ë¦¬ì†ŒìŠ¤ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
        
    @property  
    def config(self):
        """ì„¤ì • ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
        
    @property
    def tests(self):
        """í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ ë°˜í™˜"""
```

#### Spark ìœ í‹¸ë¦¬í‹° (`src/test_cicd_01/main.py`)
```python
def get_spark() -> SparkSession:
    """
    Databricks Connect ë˜ëŠ” í‘œì¤€ Spark ì„¸ì…˜ ìƒì„±
    ë¡œì»¬ ê°œë°œê³¼ í´ëŸ¬ìŠ¤í„° í™˜ê²½ì„ ëª¨ë‘ ì§€ì›
    """

def get_taxis(spark: SparkSession) -> DataFrame:
    """
    NYC Taxi ìƒ˜í”Œ ë°ì´í„° ë¡œë“œ
    """
```

### ë…¸íŠ¸ë¶ êµ¬ì„±

#### ë©”ì¸ ë…¸íŠ¸ë¶ (`src/main.ipynb`)
- ê²½ë¡œ ì„¤ì • ë…¸íŠ¸ë¶ ì‹¤í–‰
- ëª¨ë“ˆ import ë° ì‚¬ìš© ì˜ˆì œ
- PathResolver ì‚¬ìš©ë²• ë°ëª¨
- ë¦¬ì†ŒìŠ¤ íŒŒì¼ ì½ê¸° ì˜ˆì œ

#### ê²½ë¡œ ì„¤ì • ë…¸íŠ¸ë¶ (`src/set_notebook_paths.ipynb`)
- Bundle ì´ë¦„ ê¸°ë°˜ ë™ì  ê²½ë¡œ êµ¬ì„±
- sys.path ìë™ ì„¤ì •
- ë…¸íŠ¸ë¶ í™˜ê²½ì—ì„œì˜ ëª¨ë“ˆ import ì§€ì›

### í…ŒìŠ¤íŠ¸ êµ¬ì„±

#### ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- `tests/module/test_path_manager.py`: PathResolver ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
- `tests/foo/test_read_resource.py`: ë¦¬ì†ŒìŠ¤ íŒŒì¼ ì½ê¸° í…ŒìŠ¤íŠ¸

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰ í™˜ê²½
- pytest ê¸°ë°˜ í…ŒìŠ¤íŠ¸ í”„ë ˆì„ì›Œí¬
- `pytest.ini`ë¥¼ í†µí•œ í…ŒìŠ¤íŠ¸ ê²½ë¡œ ë° Python ê²½ë¡œ ì„¤ì •
- ê°œë°œ ì˜ì¡´ì„±ì€ `requirements-dev.txt`ì— ì •ì˜

### Bundle ì„¤ì •

#### Databricks Bundle (`databricks.yml`)
- ê°œë°œ/í”„ë¡œë•ì…˜ í™˜ê²½ ë¶„ë¦¬
- Git ê¸°ë°˜ ì†ŒìŠ¤ ê´€ë¦¬ ì„¤ì •
- Job ë° ë¦¬ì†ŒìŠ¤ ì •ì˜ í¬í•¨

#### Job ì •ì˜ (`resources/test_cicd_01.job.yml`)
- ë…¸íŠ¸ë¶ ê¸°ë°˜ ì‘ì—… ì •ì˜
- í í™œì„±í™” ì„¤ì •
- ì›Œí¬ìŠ¤í˜ì´ìŠ¤ ì†ŒìŠ¤ ì‚¬ìš©

## ì‚¬ìš© ì‚¬ë¡€

### 1. ë¡œì»¬ ê°œë°œ í™˜ê²½ì—ì„œ í…ŒìŠ¤íŠ¸
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements-dev.txt

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
pytest -v

# íŠ¹ì • ëª¨ë“ˆ í…ŒìŠ¤íŠ¸
pytest tests/module/ -v
```

### 2. Databricks ë…¸íŠ¸ë¶ì—ì„œ ëª¨ë“ˆ ì‚¬ìš©
```python
# ë…¸íŠ¸ë¶ ì²« ë²ˆì§¸ ì…€ì—ì„œ ì‹¤í–‰
%run ./set_notebook_paths

# ì´í›„ ì…€ì—ì„œ ëª¨ë“ˆ import ê°€ëŠ¥
from module.path_manager import PathResolver
from foo.bar import parse_bar
```

### 3. Bundle ë°°í¬ ë° ì‹¤í–‰
```bash
# ê°œë°œ í™˜ê²½ ë°°í¬
databricks bundle deploy --target dev

# Job ì‹¤í–‰
databricks bundle run test_cicd_01_job

# ë°°í¬ ìƒíƒœ í™•ì¸
databricks bundle validate
```

## í™•ì¥ ê°€ëŠ¥ì„±

ì´ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë°©í–¥ìœ¼ë¡œ í™•ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

1. **ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤ ì—°ë™**: Delta Lake, ì™¸ë¶€ ë°ì´í„°ë² ì´ìŠ¤ ë“±
2. **MLflow í†µí•©**: ëª¨ë¸ í•™ìŠµ ë° ë°°í¬ íŒŒì´í”„ë¼ì¸
3. **DLT íŒŒì´í”„ë¼ì¸**: Delta Live Tablesë¥¼ í™œìš©í•œ ë°ì´í„° íŒŒì´í”„ë¼ì¸
4. **ëª¨ë‹ˆí„°ë§ ë° ì•Œë¦¼**: Job ì‹¤í–‰ ìƒíƒœ ëª¨ë‹ˆí„°ë§
5. **ë³´ì•ˆ ê°•í™”**: Secret ê´€ë¦¬, ì ‘ê·¼ ê¶Œí•œ ì œì–´

## ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. ëª¨ë“ˆ import ì˜¤ë¥˜
```python
# í•´ê²°ë°©ë²•: ë…¸íŠ¸ë¶ì—ì„œ ê²½ë¡œ ì„¤ì • ì‹¤í–‰
%run ./set_notebook_paths
```

#### 2. ë¦¬ì†ŒìŠ¤ íŒŒì¼ ì ‘ê·¼ ì˜¤ë¥˜
```python
# PathResolver ì‚¬ìš© ê¶Œì¥
from module.path_manager import PathResolver
paths = PathResolver()
config_path = paths.resources / 'config.yml'
```

#### 3. Bundle ë°°í¬ ì‹¤íŒ¨
```bash
# ì„¤ì • ê²€ì¦
databricks bundle validate

# ì¸ì¦ ìƒíƒœ í™•ì¸
databricks auth profiles
```

## ê¸°ì—¬í•˜ê¸°

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ë¼ì´ì„ ìŠ¤

ì´ í”„ë¡œì íŠ¸ëŠ” MIT ë¼ì´ì„ ìŠ¤ í•˜ì— ë°°í¬ë©ë‹ˆë‹¤. ìì„¸í•œ ë‚´ìš©ì€ `LICENSE` íŒŒì¼ì„ ì°¸ì¡°í•˜ì„¸ìš”.
